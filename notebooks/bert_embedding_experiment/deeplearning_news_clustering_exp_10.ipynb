{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask in c:\\programdata\\anaconda3\\lib\\site-packages (2022.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask) (6.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask) (0.11.2)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask) (2022.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask) (21.3)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask) (2.0.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->dask) (3.0.4)\n",
      "Requirement already satisfied: locket in c:\\programdata\\anaconda3\\lib\\site-packages (from partd>=0.3.10->dask) (0.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: dask[dataframe] in c:\\programdata\\anaconda3\\lib\\site-packages (2022.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (21.3)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (2022.2.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (0.11.2)\n",
      "Requirement already satisfied: partd>=0.3.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (1.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (6.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (1.21.5)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (1.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->dask[dataframe]) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0->dask[dataframe]) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0->dask[dataframe]) (2.8.2)\n",
      "Requirement already satisfied: locket in c:\\programdata\\anaconda3\\lib\\site-packages (from partd>=0.3.10->dask[dataframe]) (0.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.0->dask[dataframe]) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: dask[complete] in c:\\programdata\\anaconda3\\lib\\site-packages (2022.2.1)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[complete]) (2022.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[complete]) (6.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[complete]) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[complete]) (21.3)\n",
      "Requirement already satisfied: toolz>=0.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[complete]) (0.11.2)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[complete]) (2.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[complete]) (2.11.3)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[complete]) (1.4.2)\n",
      "Requirement already satisfied: bokeh>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[complete]) (2.4.2)\n",
      "Requirement already satisfied: numpy>=1.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[complete]) (1.21.5)\n",
      "Requirement already satisfied: distributed==2022.02.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[complete]) (2022.2.1)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2022.02.1->dask[complete]) (1.0.2)\n",
      "Requirement already satisfied: click>=6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2022.02.1->dask[complete]) (8.0.4)\n",
      "Requirement already satisfied: zict>=0.1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2022.02.1->dask[complete]) (2.0.0)\n",
      "Requirement already satisfied: psutil>=5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2022.02.1->dask[complete]) (5.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2022.02.1->dask[complete]) (61.2.0)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2022.02.1->dask[complete]) (2.4.0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2022.02.1->dask[complete]) (6.1)\n",
      "Requirement already satisfied: tblib>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2022.02.1->dask[complete]) (1.7.0)\n",
      "Requirement already satisfied: pillow>=7.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from bokeh>=2.1.1->dask[complete]) (9.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from bokeh>=2.1.1->dask[complete]) (4.1.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click>=6.6->distributed==2022.02.1->dask[complete]) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->dask[complete]) (2.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->dask[complete]) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0->dask[complete]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0->dask[complete]) (2021.3)\n",
      "Requirement already satisfied: locket in c:\\programdata\\anaconda3\\lib\\site-packages (from partd>=0.3.10->dask[complete]) (0.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.0->dask[complete]) (1.16.0)\n",
      "Requirement already satisfied: heapdict in c:\\programdata\\anaconda3\\lib\\site-packages (from zict>=0.1.3->distributed==2022.02.1->dask[complete]) (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: dask[distributed] in c:\\programdata\\anaconda3\\lib\\site-packages (2022.2.1)\n",
      "Requirement already satisfied: toolz>=0.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[distributed]) (0.11.2)\n",
      "Requirement already satisfied: partd>=0.3.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[distributed]) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[distributed]) (21.3)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[distributed]) (2022.2.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[distributed]) (2.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[distributed]) (6.0)\n",
      "Requirement already satisfied: distributed==2022.02.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[distributed]) (2022.2.1)\n",
      "Requirement already satisfied: psutil>=5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2022.02.1->dask[distributed]) (5.8.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2022.02.1->dask[distributed]) (1.7.0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2022.02.1->dask[distributed]) (6.1)\n",
      "Requirement already satisfied: click>=6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2022.02.1->dask[distributed]) (8.0.4)\n",
      "Requirement already satisfied: zict>=0.1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2022.02.1->dask[distributed]) (2.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2022.02.1->dask[distributed]) (61.2.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2022.02.1->dask[distributed]) (1.0.2)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2022.02.1->dask[distributed]) (2.11.3)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed==2022.02.1->dask[distributed]) (2.4.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click>=6.6->distributed==2022.02.1->dask[distributed]) (0.4.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->dask[distributed]) (3.0.4)\n",
      "Requirement already satisfied: locket in c:\\programdata\\anaconda3\\lib\\site-packages (from partd>=0.3.10->dask[distributed]) (0.2.1)\n",
      "Requirement already satisfied: heapdict in c:\\programdata\\anaconda3\\lib\\site-packages (from zict>=0.1.3->distributed==2022.02.1->dask[distributed]) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->distributed==2022.02.1->dask[distributed]) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: cloudpickle in c:\\programdata\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: graphviz in c:\\programdata\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dask\n",
    "%pip install dask[dataframe]\n",
    "%pip install dask[complete]\n",
    "%pip install dask[distributed]\n",
    "%pip install cloudpickle\n",
    "%pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\programdata\\anaconda3\\lib\\site-packages (4.22.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.9.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: pytorch_transformers in c:\\programdata\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: boto3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch_transformers) (1.21.32)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch_transformers) (1.12.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch_transformers) (2.27.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch_transformers) (4.64.0)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch_transformers) (2022.3.15)\n",
      "Requirement already satisfied: sacremoses in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch_transformers) (0.0.53)\n",
      "Requirement already satisfied: sentencepiece in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch_transformers) (0.1.97)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch_transformers) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.0.0->pytorch_transformers) (4.1.1)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->pytorch_transformers) (0.5.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->pytorch_transformers) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.32 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->pytorch_transformers) (1.24.32)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.25.0,>=1.24.32->boto3->pytorch_transformers) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.25.0,>=1.24.32->boto3->pytorch_transformers) (1.26.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.32->boto3->pytorch_transformers) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pytorch_transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pytorch_transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pytorch_transformers) (2.0.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->pytorch_transformers) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->pytorch_transformers) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->sacremoses->pytorch_transformers) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install pytorch_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import dask.multiprocessing\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import torch\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from transformers import BertForSequenceClassification, BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init hardware resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "  \n",
    "  # Tell PyTorch to use the GPU.\n",
    "  device = torch.device(\"cuda\")\n",
    "\n",
    "  print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "  print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "  # If not...\n",
    "  print('No GPU available, using the CPU instead.')\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1727888\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>026f4c15-37a9-459d-a944-03bde29a5c59</td>\n",
       "      <td>அமைச்சின் பணிகளை முன்னெடுப்பதற்கு கௌர அமைச்சர்...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0df3b73b-b08a-4357-bd6d-3bd94f8d4e58</td>\n",
       "      <td>இவ்வமைச்சு இல 40  புத்கமுவ வீதி  இராஜகிரிய எனு...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  026f4c15-37a9-459d-a944-03bde29a5c59   \n",
       "1  0df3b73b-b08a-4357-bd6d-3bd94f8d4e58   \n",
       "\n",
       "                                                news  \n",
       "0  அமைச்சின் பணிகளை முன்னெடுப்பதற்கு கௌர அமைச்சர்...  \n",
       "1  இவ்வமைச்சு இல 40  புத்கமுவ வீதி  இராஜகிரிய எனு...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtypes = {\n",
    "    'id': str,\n",
    "    'news': str\n",
    "}\n",
    "\n",
    "csv_file = '../../data/news_with_header.csv'\n",
    "df = pd.read_csv(csv_file, dtype=dtypes)\n",
    "\n",
    "print(len(df))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO TEST\n",
    "# df = df.iloc[:50]\n",
    "# len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the pretained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The name of the folder containing the model files.\n",
    "pretrained_model = 'bert-base-multilingual-uncased'\n",
    "\n",
    "# Load our fine-tuned model, and configure it to return the \"hidden states\",\n",
    "# from which we will be taking our text embeddings.\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model,\n",
    "    output_hidden_states=True,  # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Load the tokenizer.\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
    "\n",
    "# Copy the model to the GPU.\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import truncate\n",
    "\n",
    "\n",
    "def news_to_embedding(tokenizer, model, in_text):\n",
    "    #   Uses the provided BERT `model` and `tokenizer` to generate a vector \n",
    "    #   representation of the input string, `in_text`.\n",
    "    #   Returns the vector stored as a numpy ndarray.\n",
    "  \n",
    "    # ===========================\n",
    "    #    STEP 1: Tokenization\n",
    "    # ===========================\n",
    "    tokens = tokenizer.tokenize(in_text)\n",
    "    if (len(tokens) > 510):\n",
    "        tokens = tokens[:128] + tokens[-382:]\n",
    "\n",
    "    MAX_LEN = 512\n",
    "\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Truncate the sentence to MAX_LEN if necessary.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end. (After truncating!)\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    input_ids = tokenizer.encode(\n",
    "        tokens,                   # Sentence to encode.\n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "        max_length=MAX_LEN,       # Truncate all sentences.\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    # Pad our input tokens. Truncation was handled above by the `encode`\n",
    "    # function, which also makes sure that the `[SEP]` token is placed at the\n",
    "    # end *after* truncating.\n",
    "    # Note: `pad_sequences` expects a list of lists, but we only have one\n",
    "    # piece of text, so we surround `input_ids` with an extra set of brackets.\n",
    "    results = pad_sequences([input_ids], maxlen=MAX_LEN, dtype=\"long\",\n",
    "                            truncating=\"post\", padding=\"post\")\n",
    "    \n",
    "    # Remove the outer list.\n",
    "    input_ids = results[0]\n",
    "    \n",
    "    # Create attention masks\n",
    "    attn_mask = [int(i > 0) for i in input_ids]\n",
    "    \n",
    "    # Cast to tensors.\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attn_mask = torch.tensor(attn_mask)\n",
    "\n",
    "    # Add an extra dimension for the \"batch\" (even though there is only one\n",
    "    # input in this batch.)\n",
    "    input_ids = input_ids.unsqueeze(0)\n",
    "    attn_mask = attn_mask.unsqueeze(0)\n",
    "\n",
    "    # ===========================\n",
    "    #    STEP 2: BERT Model\n",
    "    # ===========================\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Copy the inputs to the GPU\n",
    "    # Note -- I got stuck here for a while because I didn't assign the result\n",
    "    # back to the variable! Geez!\n",
    "    input_ids = input_ids.to(device)\n",
    "    attn_mask = attn_mask.to(device)\n",
    "\n",
    "    # Telling the model not to build the backwards graph will make this\n",
    "    # a little quicker.\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, return hidden states and predictions.\n",
    "        # This will return the logits rather than the loss because we have\n",
    "        # not provided labels.\n",
    "        logits, encoded_layers = model(\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=attn_mask,\n",
    "            return_dict=False)\n",
    "\n",
    "    # Retrieve our sentence embedding--take the `[CLS]` embedding from the final\n",
    "    # layer.\n",
    "    layer_i = 12 # The last BERT layer before the classifier.\n",
    "    batch_i = 0  # Only one input in the batch.\n",
    "    token_i = 0  # The first token, corresponding to [CLS]\n",
    "\n",
    "    # Grab the embedding.\n",
    "    vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "    \n",
    "    # Move to the CPU and convert to numpy ndarray.\n",
    "    vec = vec.detach().cpu().numpy()\n",
    "\n",
    "    return(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITH OUT DASK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the onw news from the list.\n",
    "input_text = df['news'].iloc[10]\n",
    "\n",
    "print('Getting embedding for news:\\n\\n', input_text)\n",
    "\n",
    "# Use the BERT model and tokenizer to generate an embedding for `input_text`.\n",
    "vec = news_to_embedding(tokenizer, model, input_text)\n",
    "\n",
    "print('\\nDone. Embedding shape:', str(vec.shape))\n",
    "print('\\nDone. news embedding vector:\\n', str(vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch process news to extract embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the set of embeddings.\n",
    "embeddings = []\n",
    "\n",
    "num_news = len(df['news'])\n",
    "print('Generating news embeddings for all {:,} news...'.format(num_news))\n",
    "\n",
    "# For each row of the dataframe...\n",
    "for idx, row in tqdm(df.iterrows()):\n",
    "  # Vectorize this news.\n",
    "  vec = news_to_embedding(tokenizer, model, row.news)\n",
    "\n",
    "  # Store the embeddings.\n",
    "  embeddings.append(vec)\n",
    "\n",
    "  # # Store the id\n",
    "  # new_id_row = [row.id]\n",
    "  # df_for_ids = pd.DataFrame(new_id_row, columns=['ids'])\n",
    "  # df_for_ids.to_csv('../../data/processed_ids.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of vectors into a 2D array.\n",
    "vecs = np.stack(embeddings)\n",
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../../data/vectors/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "  os.makedirs(output_dir)\n",
    "\n",
    "# Use numpy to write out the matrix of embeddings.\n",
    "print(f'Saving vec to: {output_dir}embeddings.npy')\n",
    "np.save(f'{output_dir}embeddings.npy', vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITH DASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f410d54692d4842843cf8f17d155f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel Tasks:  50\n"
     ]
    }
   ],
   "source": [
    "# WITH DASK\n",
    "parallel_tasks = []\n",
    "for idx, row in tqdm(df.iterrows()):\n",
    "  task = dask.delayed(news_to_embedding)(tokenizer, model, row.news)\n",
    "  parallel_tasks.append(task)\n",
    "\n",
    "print('Parallel Tasks: ', len(parallel_tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTED\n",
      "[########################################] | 100% Completed |  1min 18.9s\n",
      "DONE\n",
      "CPU times: total: 8min 11s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('STARTED')\n",
    "\n",
    "with ProgressBar():\n",
    "  results = dask.compute(*parallel_tasks)\n",
    "  \n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Result Size: ', len(results))\n",
    "print('Result: ', results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = np.stack(results)\n",
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../../data/vectors/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "  os.makedirs(output_dir)\n",
    "\n",
    "# Use numpy to write out the matrix of embeddings.\n",
    "print(f'Saving vec to: {output_dir}embeddings.npy')\n",
    "np.save(f'{output_dir}embeddings.npy', vecs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
