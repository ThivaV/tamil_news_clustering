{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["vKhlMuAGkjIJ","4h0mf09aljP8","jO4Bd9Jtqff5","LgSmqO_Yqi8V"],"machine_shape":"hm","mount_file_id":"1weO65D_MGkmL5nsMaA3CMYqMtv1xv9s0","authorship_tag":"ABX9TyMS52E/s4gkOVeDGWE7CkPx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"249c21c8f0fe41828b879cfe88b016a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ce793d7f14c3436bb7e5972297f90add","IPY_MODEL_78587743fda142d18710b81e2a696280","IPY_MODEL_1f1de4071e4b4cbd8e6dcd33be58d1ee"],"layout":"IPY_MODEL_7613f31cdb3347db88e72b782175ee96"}},"ce793d7f14c3436bb7e5972297f90add":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b65421a046a3473e801a7816ec07b1d9","placeholder":"​","style":"IPY_MODEL_1a032fec717e4b09a01654f646823101","value":"Downloading: 100%"}},"78587743fda142d18710b81e2a696280":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79707bea93c647dc81331cc0f1bd1e31","max":871891,"min":0,"orientation":"horizontal","style":"IPY_MODEL_42d9d89749354dbb8dc593240bb5e484","value":871891}},"1f1de4071e4b4cbd8e6dcd33be58d1ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bde42ea4ac214ce7ae0f3c15fcedd109","placeholder":"​","style":"IPY_MODEL_9928c104f9ff43c2848cd0b44ff7232c","value":" 872k/872k [00:00&lt;00:00, 2.11MB/s]"}},"7613f31cdb3347db88e72b782175ee96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b65421a046a3473e801a7816ec07b1d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a032fec717e4b09a01654f646823101":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79707bea93c647dc81331cc0f1bd1e31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42d9d89749354dbb8dc593240bb5e484":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bde42ea4ac214ce7ae0f3c15fcedd109":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9928c104f9ff43c2848cd0b44ff7232c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7af5f27bbe2c4de2a6969ef547106f25":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_15793ee725ba419db111e6bce3064c58","IPY_MODEL_143a8af2337e4396ae29f540bafda95f","IPY_MODEL_e41c5a42ffa34712a267644e18fa1d93"],"layout":"IPY_MODEL_ca13590bfdb04254b748dc9ebc77c00a"}},"15793ee725ba419db111e6bce3064c58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7515889e3d3b4d09b64aa0356f70e9a3","placeholder":"​","style":"IPY_MODEL_bd288517d00e49d28e9e87e233d79c5d","value":"Downloading: 100%"}},"143a8af2337e4396ae29f540bafda95f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7efa157607e64432b9f8814f49e9b985","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1bb61c7b4034ae6a3f173828b7c746b","value":28}},"e41c5a42ffa34712a267644e18fa1d93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9ef0e5e7e6f4df0b65970e8ac07e085","placeholder":"​","style":"IPY_MODEL_501def06edea41e4afefeccb8fcd98a0","value":" 28.0/28.0 [00:00&lt;00:00, 1.06kB/s]"}},"ca13590bfdb04254b748dc9ebc77c00a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7515889e3d3b4d09b64aa0356f70e9a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd288517d00e49d28e9e87e233d79c5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7efa157607e64432b9f8814f49e9b985":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1bb61c7b4034ae6a3f173828b7c746b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e9ef0e5e7e6f4df0b65970e8ac07e085":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"501def06edea41e4afefeccb8fcd98a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd5cd3fca9d348eb927650f9e30b311a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c6c748a51c554220b0a0bc8021368f8e","IPY_MODEL_6232a28b8da648f49decddbf745ee70b","IPY_MODEL_202015c9e3884440a8dbb1fda148ca70"],"layout":"IPY_MODEL_5e05e2dff5904fc39b081244f0a2fcef"}},"c6c748a51c554220b0a0bc8021368f8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd25b4a777f34358bd79ac0f28fedd8c","placeholder":"​","style":"IPY_MODEL_e587644e16434835bca6be376f8c2a54","value":"Downloading: 100%"}},"6232a28b8da648f49decddbf745ee70b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6af49822b9a848a792686650d934d37d","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b271dd3389dc4225bb482344e843d280","value":625}},"202015c9e3884440a8dbb1fda148ca70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb05ef58bf144ba38cb5e7fd0f8e2763","placeholder":"​","style":"IPY_MODEL_81815deeeea542e686859eb9ae587c88","value":" 625/625 [00:00&lt;00:00, 25.4kB/s]"}},"5e05e2dff5904fc39b081244f0a2fcef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd25b4a777f34358bd79ac0f28fedd8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e587644e16434835bca6be376f8c2a54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6af49822b9a848a792686650d934d37d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b271dd3389dc4225bb482344e843d280":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb05ef58bf144ba38cb5e7fd0f8e2763":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81815deeeea542e686859eb9ae587c88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ebb9d9c3ed44849b403a648c19e7b6a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b1bd86cfcbe485fbde40bf1df656f1f","IPY_MODEL_a2c92bfc98bf4822918c515ac2c5d6ac","IPY_MODEL_1dbee443c54a4fadbf13e146e0d7544e"],"layout":"IPY_MODEL_b307474efed349debb8c24b68541cb7b"}},"4b1bd86cfcbe485fbde40bf1df656f1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c55ef02726344d94a04bfa1101cdeb4c","placeholder":"​","style":"IPY_MODEL_4378f4353d8d48568c242b9fcb6c4e75","value":"Downloading: 100%"}},"a2c92bfc98bf4822918c515ac2c5d6ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_decafa80fee34f759e05b8a85bc92232","max":672271273,"min":0,"orientation":"horizontal","style":"IPY_MODEL_14f5be1e2f344b2ba9b9135036827677","value":672271273}},"1dbee443c54a4fadbf13e146e0d7544e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df5dda98bc534b6c9dd19830dad30001","placeholder":"​","style":"IPY_MODEL_a14d968419ee422ab198a5bb6ab7247a","value":" 672M/672M [00:11&lt;00:00, 58.4MB/s]"}},"b307474efed349debb8c24b68541cb7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c55ef02726344d94a04bfa1101cdeb4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4378f4353d8d48568c242b9fcb6c4e75":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"decafa80fee34f759e05b8a85bc92232":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14f5be1e2f344b2ba9b9135036827677":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df5dda98bc534b6c9dd19830dad30001":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a14d968419ee422ab198a5bb6ab7247a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"premium","accelerator":"TPU"},"cells":[{"cell_type":"markdown","source":["## PoC - 1"],"metadata":{"id":"vKhlMuAGkjIJ"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install pytorch_transformers"],"metadata":{"id":"hPGIBps4Q3uo"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hM-EdvsnKlbK"},"outputs":[],"source":["import torch\n","from pytorch_transformers import BertTokenizer\n","from pytorch_transformers import BertModel"]},{"cell_type":"code","source":["## Load pretrained model/tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)\n","model = BertModel.from_pretrained('bert-base-multilingual-uncased', output_hidden_states=True)"],"metadata":{"id":"zPjwkJN3QXhs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define an input text\n","text = \"நான்  என்  பள்ளிக்குச்  செல்கிறேன். என் பள்ளியின் பெயர் பாரதியார் கல்வி நிலையம். நான்  பள்ளியில்  முதல்  வகுப்பில்  படிக்கிறேன்.\"\n","\n","# Add the special tokens.\n","marked_text = \"[CLS] \" + text + \" [SEP]\"\n","\n","# Split the sentence into tokens.\n","tokenized_text = tokenizer.tokenize(marked_text)\n","\n","marked_text, tokenized_text"],"metadata":{"id":"0EhcGBb_SBnE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Map the token strings to their vocabulary indeces.\n","indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n","\n","# Display the words with their indeces.\n","for tup in zip(tokenized_text, indexed_tokens):\n","  print('{:<12} {:>6,}'.format(tup[0], tup[1]))"],"metadata":{"id":"by2KTZ4WSwV8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert inputs to PyTorch tensors\n","tokens_tensor = torch.tensor([indexed_tokens])\n","\n","# Put the model in \"evaluation\" mode,meaning feed-forward operation.\n","model.eval()"],"metadata":{"id":"Hos56I_sScWu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run the text through BERT, get the output and collect all of the hidden states produced from all 12 layers.\n","with torch.no_grad():\n","  outputs = model(tokens_tensor)\n","  \n","  # can use last hidden state as word embeddings\n","  last_hidden_state = outputs[0]\n","  word_embed_1 = last_hidden_state\n","\n","  # Evaluating the model will return a different number of objects based on how it's  configured in the `from_pretrained` call earlier. \n","  # In this case, becase we set `output_hidden_states = True`, the third item will be the hidden states from all layers. \n","  # See the documentation for more details:https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n","  hidden_states = outputs[2]\n","  \n","  # initial embeddings can be taken from 0th layer of hidden states\n","  word_embed_2 = hidden_states[0]\n","  \n","  # sum of all hidden states\n","  word_embed_3 = torch.stack(hidden_states).sum(0)\n","  \n","  # sum of second to last layer\n","  word_embed_4 = torch.stack(hidden_states[2:]).sum(0)\n","  \n","  # sum of last four layer\n","  word_embed_5 = torch.stack(hidden_states[-4:]).sum(0)\n","  \n","  # concatenate last four layers\n","  word_embed_6 = torch.cat([hidden_states[i] for i in [-1,-2,-3,-4]], dim=-1)"],"metadata":{"id":"YK7DN6vjS84D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hidden_states"],"metadata":{"id":"uYCFb-TSTfAQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## PoC - 2"],"metadata":{"id":"4h0mf09aljP8"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install pytorch_transformers"],"metadata":{"id":"5vIxnUlylkwB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","# from pytorch_transformers import BertTokenizer\n","# from pytorch_transformers import BertModel\n","\n","from transformers import BertTokenizer\n","from transformers import BertModel"],"metadata":{"id":"eel0EhgDlm1x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Load pretrained model/tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)\n","model = BertModel.from_pretrained('bert-base-multilingual-uncased', output_hidden_states=True)"],"metadata":{"id":"ZeVa2kaHlozg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Method - 1"],"metadata":{"id":"jO4Bd9Jtqff5"}},{"cell_type":"code","source":["# Define an input text\n","text = \"நான்  என்  பள்ளிக்குச்  செல்கிறேன். என் பள்ளியின் பெயர் பாரதியார் கல்வி நிலையம். நான்  பள்ளியில்  முதல்  வகுப்பில்  படிக்கிறேன்.\"\n","\n","encoding = tokenizer.encode(text)\n","print(encoding)"],"metadata":{"id":"fktkZNh7lqxT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(tokenizer.convert_ids_to_tokens(encoding))"],"metadata":{"id":"3KUdqYA0nE3c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Method - 2"],"metadata":{"id":"LgSmqO_Yqi8V"}},{"cell_type":"code","source":["# Define an input text\n","text = \"நான்  என்  பள்ளிக்குச்  செல்கிறேன். என் பள்ளியின் பெயர் பாரதியார் கல்வி நிலையம். நான்  பள்ளியில்  முதல்  வகுப்பில்  படிக்கிறேன்.\"\n","# text = \"நான்  என்  பள்ளிக்குச்  செல்கிறேன்.\""],"metadata":{"id":"UTuRvWGFusPN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoding_formatted = tokenizer.encode(text,\n","                                      add_special_tokens = True,\n","                                      max_length = 512, \n","                                      truncation = True, \n","                                      padding = \"max_length\"\n","                                    )\n","print(encoding_formatted)"],"metadata":{"id":"gKjJYOm2m3YM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["token_text = tokenizer.convert_ids_to_tokens(encoding_formatted)\n","print(token_text)"],"metadata":{"id":"USfb-gnxpglS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["indexed_tokens = tokenizer.convert_tokens_to_ids(token_text)\n","\n","# Display the words with their indeces.\n","for tup in zip(token_text, indexed_tokens):\n","  print('{:<12} {:>6,}'.format(tup[0], tup[1]))"],"metadata":{"id":"ui3Rf_X2qzNo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert inputs to PyTorch tensors\n","tokens_tensor = torch.tensor([indexed_tokens])\n","\n","# Put the model in \"evaluation\" mode,meaning feed-forward operation.\n","model.eval()"],"metadata":{"id":"vWQqFgtpsHNJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run the text through BERT, get the output and collect all of the hidden states produced from all 12 layers.\n","with torch.no_grad():\n","  outputs = model(tokens_tensor)\n","  \n","  # can use last hidden state as word embeddings\n","  last_hidden_state = outputs[0]\n","  word_embed_1 = last_hidden_state\n","\n","  # Evaluating the model will return a different number of objects based on how it's  configured in the `from_pretrained` call earlier. \n","  # In this case, becase we set `output_hidden_states = True`, the third item will be the hidden states from all layers. \n","  # See the documentation for more details:https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n","  hidden_states = outputs[2]\n","  \n","  # initial embeddings can be taken from 0th layer of hidden states\n","  word_embed_2 = hidden_states[0]\n","  \n","  # sum of all hidden states\n","  word_embed_3 = torch.stack(hidden_states).sum(0)\n","  \n","  # sum of second to last layer\n","  word_embed_4 = torch.stack(hidden_states[2:]).sum(0)\n","  \n","  # sum of last four layer\n","  word_embed_5 = torch.stack(hidden_states[-4:]).sum(0)\n","  \n","  # concatenate last four layers\n","  word_embed_6 = torch.cat([hidden_states[i] for i in [-1,-2,-3,-4]], dim=-1)"],"metadata":{"id":"w2BA76QDt0jS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word_embed_2"],"metadata":{"id":"cJm816_wt3iM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Actual Workings"],"metadata":{"id":"QIq2pMTnkb47"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive')"],"metadata":{"id":"bmW-SHM-ku-L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers\n","!pip install pytorch_transformers"],"metadata":{"id":"JqT1xgfjTgx5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664791265043,"user_tz":-330,"elapsed":19666,"user":{"displayName":"Thivaharan Varatharajan","userId":"09806760569647013642"}},"outputId":"1436b1fa-4f8a-4949-be2f-d984369d7107"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.9.0\n","  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 78.1 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 66.0 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch_transformers\n","  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n","\u001b[K     |████████████████████████████████| 176 kB 5.2 MB/s \n","\u001b[?25hCollecting boto3\n","  Downloading boto3-1.24.84-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 80.3 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 84.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2022.6.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 77.3 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.12.1+cu113)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.64.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (4.1.1)\n","Collecting s3transfer<0.7.0,>=0.6.0\n","  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 8.6 MB/s \n","\u001b[?25hCollecting botocore<1.28.0,>=1.27.84\n","  Downloading botocore-1.27.84-py3-none-any.whl (9.2 MB)\n","\u001b[K     |████████████████████████████████| 9.2 MB 68.5 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 80.9 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.84->boto3->pytorch_transformers) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.84->boto3->pytorch_transformers) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 80.1 MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2022.6.15)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=5a22eae92f74e90b7e423765dcffbd27806e76c211898bc0f34dc0999d1b0826\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, pytorch-transformers\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed boto3-1.24.84 botocore-1.27.84 jmespath-1.0.1 pytorch-transformers-1.2.0 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.97 urllib3-1.25.11\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","import torch\n","\n","from transformers import BertTokenizer\n","from transformers import BertModel\n","\n","from tqdm.notebook import tqdm\n","tqdm.pandas()"],"metadata":{"id":"JAz7yJvrkpGk","executionInfo":{"status":"ok","timestamp":1664791279346,"user_tz":-330,"elapsed":2,"user":{"displayName":"Thivaharan Varatharajan","userId":"09806760569647013642"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["data_uri = '/content/drive/MyDrive/Colab Notebooks/deeplearning_news_clustering/data/allData-19-08-27.ta'\n","\n","df = pd.read_csv(data_uri, header=None, names=['news'])\n","len(df)"],"metadata":{"id":"FdFxSttOk6PW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664791307609,"user_tz":-330,"elapsed":11881,"user":{"displayName":"Thivaharan Varatharajan","userId":"09806760569647013642"}},"outputId":"99561724-70b9-4703-b776-fcd3515cc2df"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1727888"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["df['news'] = df['news'].str.strip()\n","df.head(), len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYBebJj3x0ci","executionInfo":{"status":"ok","timestamp":1664791337860,"user_tz":-330,"elapsed":2333,"user":{"displayName":"Thivaharan Varatharajan","userId":"09806760569647013642"}},"outputId":"d7b72a25-9e32-4b00-e670-df7caaa964ea"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                                                news\n"," 0  அமைச்சின் பணிகளை முன்னெடுப்பதற்கு கௌர அமைச்சர்...\n"," 1  இவ்வமைச்சு இல 40  புத்கமுவ வீதி  இராஜகிரிய எனு...\n"," 2  தேசிய மொழிகள் மற்றும் சமூக ஒருமைப்பாட்டு அமைச்...\n"," 3  தேசிய மொழிகள்  சமூக ஒருமைப்பாடு தொடர்பான கொள்க...\n"," 4  குறித்த தேசிய நோக்கங்களை எய்தும் பொருட்டு தேசி..., 1727888)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["## Load pretrained model/tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)\n","model = BertModel.from_pretrained('bert-base-multilingual-uncased', output_hidden_states=True)"],"metadata":{"id":"6Ct5Ri5vkqku","colab":{"base_uri":"https://localhost:8080/","height":217,"referenced_widgets":["249c21c8f0fe41828b879cfe88b016a4","ce793d7f14c3436bb7e5972297f90add","78587743fda142d18710b81e2a696280","1f1de4071e4b4cbd8e6dcd33be58d1ee","7613f31cdb3347db88e72b782175ee96","b65421a046a3473e801a7816ec07b1d9","1a032fec717e4b09a01654f646823101","79707bea93c647dc81331cc0f1bd1e31","42d9d89749354dbb8dc593240bb5e484","bde42ea4ac214ce7ae0f3c15fcedd109","9928c104f9ff43c2848cd0b44ff7232c","7af5f27bbe2c4de2a6969ef547106f25","15793ee725ba419db111e6bce3064c58","143a8af2337e4396ae29f540bafda95f","e41c5a42ffa34712a267644e18fa1d93","ca13590bfdb04254b748dc9ebc77c00a","7515889e3d3b4d09b64aa0356f70e9a3","bd288517d00e49d28e9e87e233d79c5d","7efa157607e64432b9f8814f49e9b985","b1bb61c7b4034ae6a3f173828b7c746b","e9ef0e5e7e6f4df0b65970e8ac07e085","501def06edea41e4afefeccb8fcd98a0","fd5cd3fca9d348eb927650f9e30b311a","c6c748a51c554220b0a0bc8021368f8e","6232a28b8da648f49decddbf745ee70b","202015c9e3884440a8dbb1fda148ca70","5e05e2dff5904fc39b081244f0a2fcef","fd25b4a777f34358bd79ac0f28fedd8c","e587644e16434835bca6be376f8c2a54","6af49822b9a848a792686650d934d37d","b271dd3389dc4225bb482344e843d280","bb05ef58bf144ba38cb5e7fd0f8e2763","81815deeeea542e686859eb9ae587c88","8ebb9d9c3ed44849b403a648c19e7b6a","4b1bd86cfcbe485fbde40bf1df656f1f","a2c92bfc98bf4822918c515ac2c5d6ac","1dbee443c54a4fadbf13e146e0d7544e","b307474efed349debb8c24b68541cb7b","c55ef02726344d94a04bfa1101cdeb4c","4378f4353d8d48568c242b9fcb6c4e75","decafa80fee34f759e05b8a85bc92232","14f5be1e2f344b2ba9b9135036827677","df5dda98bc534b6c9dd19830dad30001","a14d968419ee422ab198a5bb6ab7247a"]},"executionInfo":{"status":"ok","timestamp":1664791394289,"user_tz":-330,"elapsed":16208,"user":{"displayName":"Thivaharan Varatharajan","userId":"09806760569647013642"}},"outputId":"fc948f58-8b27-4e02-9769-cd969ad5fe4f"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/872k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"249c21c8f0fe41828b879cfe88b016a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7af5f27bbe2c4de2a6969ef547106f25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd5cd3fca9d348eb927650f9e30b311a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/672M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ebb9d9c3ed44849b403a648c19e7b6a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["# Put the model in \"evaluation\" mode,meaning feed-forward operation.\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"edw4o6u1SJRB","executionInfo":{"status":"ok","timestamp":1664791403437,"user_tz":-330,"elapsed":414,"user":{"displayName":"Thivaharan Varatharajan","userId":"09806760569647013642"}},"outputId":"af70414f-c50a-4a20-dba0-84e128a07e67"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(105879, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["def get_vectors(news):\n","  encoding = tokenizer.encode(news,\n","                              add_special_tokens = True,\n","                              max_length = 512, \n","                              truncation = True, \n","                              padding = \"max_length\"\n","                            )\n","  token_text = tokenizer.convert_ids_to_tokens(encoding)\n","  indexed_tokens = tokenizer.convert_tokens_to_ids(token_text)\n","\n","  # Convert inputs to PyTorch tensors\n","  tokens_tensor = torch.tensor([indexed_tokens])\n","\n","  # Run the text through BERT, get the output and collect all of the hidden states produced from all 12 layers.\n","  with torch.no_grad():\n","    outputs = model(tokens_tensor)\n","    \n","    # can use last hidden state as word embeddings\n","    last_hidden_state = outputs[0]\n","    word_embed_1 = last_hidden_state\n","\n","    # Evaluating the model will return a different number of objects based on how it's  configured in the `from_pretrained` call earlier. \n","    # In this case, becase we set `output_hidden_states = True`, the third item will be the hidden states from all layers. \n","    # See the documentation for more details:https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n","    hidden_states = outputs[2]\n","    \n","    # initial embeddings can be taken from 0th layer of hidden states\n","    word_embed_2 = hidden_states[0]\n","    return word_embed_2"],"metadata":{"id":"cdZwGrjVk9CO","executionInfo":{"status":"ok","timestamp":1664791422515,"user_tz":-330,"elapsed":685,"user":{"displayName":"Thivaharan Varatharajan","userId":"09806760569647013642"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["df['vec'] = df['news'].progress_apply(get_vectors)"],"metadata":{"id":"-Ao7sfXyw2-o","colab":{"base_uri":"https://localhost:8080/","height":165},"executionInfo":{"status":"error","timestamp":1664796988746,"user_tz":-330,"elapsed":454,"user":{"displayName":"Thivaharan Varatharajan","userId":"09806760569647013642"}},"outputId":"61704852-5bed-48ef-dade-49143a20650d"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a69a1b3734d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vec'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'news'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}]},{"cell_type":"code","source":["# base_url = r'D:\\repo\\R&D\\deeplearning_news_clustering\\data\\vec.csv'\n","base_url = '/content/drive/MyDrive/Colab Notebooks/deeplearning_news_clustering/vectors/vec.csv'\n","df.to_csv(base_url, encoding='utf-8')"],"metadata":{"id":"M2gzguWjw5bu"},"execution_count":null,"outputs":[]}]}