{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install dask\n",
    "%pip install dask[dataframe]\n",
    "%pip install dask[complete]\n",
    "%pip install dask[distributed]\n",
    "%pip install cloudpickle\n",
    "%pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "%pip install pytorch_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the imports\n",
    "try:\n",
    "    import os\n",
    "    import json\n",
    "    import math\n",
    "    import dask\n",
    "    from dask.distributed import Client\n",
    "    import dask.dataframe as dd\n",
    "    from dask.diagnostics import ProgressBar\n",
    "    import dask.multiprocessing\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    from transformers import BertTokenizer\n",
    "    from transformers import BertModel\n",
    "    from tqdm.notebook import tqdm\n",
    "    tqdm.pandas()\n",
    "except Exception as ex:\n",
    "    print('Some modules are missing : {}'.format(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = os.path.getsize('../data/allData-19-08-27.ta') / math.pow(1024, 3)\n",
    "print('Size in GB: {}'.format(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers = 5, threads_per_worker = 1, processes = False, memory_limit = '2GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'id': str,\n",
    "    'news': str    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_csv('../data/news_with_header.csv',\n",
    "                 names=['id', 'news'], dtype=dtypes)\n",
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pretrained model/tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-multilingual-uncased', do_lower_case=True)\n",
    "model = BertModel.from_pretrained(\n",
    "    'bert-base-multilingual-uncased', output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the model in \"evaluation\" mode,meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(row):\n",
    "  print('e')\n",
    "  encoding = tokenizer.encode(row['news'], add_special_tokens=True, max_length=512, truncation=True, padding=\"max_length\")\n",
    "  token_text = tokenizer.convert_ids_to_tokens(encoding)\n",
    "  indexed_tokens = tokenizer.convert_tokens_to_ids(token_text)\n",
    "\n",
    "  # Convert inputs to PyTorch tensors\n",
    "  tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "  # Run the text through BERT, get the output and collect all of the hidden states produced from all 12 layers.\n",
    "  with torch.no_grad():\n",
    "    outputs = model(tokens_tensor)\n",
    "\n",
    "    # Evaluating the model will return a different number of objects based on how it's  configured in the `from_pretrained` call earlier.\n",
    "    # In this case, becase we set `output_hidden_states = True`, the third item will be the hidden states from all layers.\n",
    "    # See the documentation for more details:https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "    hidden_states = outputs[2]\n",
    "\n",
    "    # initial embeddings can be taken from 0th layer of hidden states\n",
    "    word_embed = hidden_states[0]\n",
    "    \n",
    "    output_path = '../data/vectors/{id}.npy'.format(id = row['id'])\n",
    "    np.save(output_path, word_embed)\n",
    "    # return word_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_task = []\n",
    "parallel_task.append(dask.delayed(get_vectors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vectors = dask.delayed(get_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ddf.map_partitions(get_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[0][0][1].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dab48d2a0538fbdd6d3e80281ebd5b12bcb6aa59bd0b0f501333d541a04279e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
